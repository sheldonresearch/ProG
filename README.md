<h1 align="center">
  <img height="150" src="/Logo.jpg?sanitize=true" />
</h1>





<p align="left">

![](https://img.shields.io/badge/Latest_version-v0.1.5-red)
![Testing Status](https://img.shields.io/badge/docs-in_progress-green)
![Testing Status](https://img.shields.io/badge/pypi_package-in_progress-green)
![Testing Status](https://img.shields.io/badge/PyTorch-v1.13.1-red)
![Testing Status](https://img.shields.io/badge/license-MIT-blue)
![Testing Status](https://img.shields.io/badge/python->=3.9-red)

</p>


<p align="left">
  
| **[Quick Start](#quick-start)** 
| **[Website](https://graphprompt.github.io/)** | **[Paper](https://arxiv.org/abs/2307.01504)**
| **[Video](https://www.youtube.com/watch?v=MFL0ynk1BKs)**
| **[Media Coverage](#media-coverage)**
| **[Call For Contribution](#call-for-contributors)** |


</p>





<h3>ProG: A Python Library for Multi-task Graph Prompting</h3> 

**ProG** (_Prompt Graph_) is a library built upon PyTorch to easily conduct single or multi-task prompting for 
pre-trained Graph Neural Networks (GNNs). The idea is derived from the paper: Xiangguo Sun, Hong Cheng, Jia Li,
etc. [All in One: Multi-task Prompting for Graph Neural Networks](https://arxiv.org/abs/2307.01504). KDD2023 (ğŸ”¥  _**Best Research Paper Award**, which is the first time for Hong Kong and Mainland China_), in which
they released their [raw codes](https://anonymous.4open.science/r/mpg/README.md). This repository is a redesigned and enhanced version of the raw
codes with [extremely huge changes and updates](https://github.com/sheldonresearch/ProG/blob/main/History.md#13-jul-2023)

<br>




<h3>ğŸŒŸProG++ğŸŒŸ: A Unified Python Library for Graph Prompting</h3> 

**ProG++** is an extended library with **ProG**, which supports more graph prompt models. Currently, **ProG++** is now in its beta version (a little baby: [ProG Plus](https://github.com/Barristen/Prog_plus)), and we will merge ``ProG Plus`` to ``ProG`` in the near future. Some implemented models are as follows (_We are now implementing more related models and we will keep integrating more models to ProG++_):  

>- [All in One] X. Sun, H. Cheng, J. Li, B. Liu, and J. Guan, â€œAll in One: Multi-Task Prompting for Graph Neural Networks,â€ KDD, 2023
>- [GPF Plus] T. Fang, Y. Zhang, Y. Yang, C. Wang, and L. Chen, â€œUniversal Prompt Tuning for Graph Neural Networks,â€ NeurIPS, 2023.
>- [GraphPrompt] Liu Z, Yu X, Fang Y, et al. Graphprompt: Unifying pre-training and downstream tasks for graph neural networks. The Web Conference, 2023.
>- [GPPT] M. Sun, K. Zhou, X. He, Y. Wang, and X. Wang, â€œGPPT: Graph Pre-Training and Prompt Tuning to Generalize Graph Neural Networks,â€ KDD, 2022
>- [GPF] T. Fang, Y. Zhang, Y. Yang, and C. Wang, â€œPrompt tuning for graph neural networks,â€ arXiv preprint, 2022.


<br>

<h3 align="center">
  
![](https://img.shields.io/badge/News-red)
ğŸ¶We released a comprehensive survey on graph prompt!

</h3>

>Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, Jia Li.
>
>Graph Prompt Learning: A Comprehensive Survey and Beyond
>
>in arXiv [https://arxiv.org/abs/2311.16534](https://arxiv.org/abs/2311.16534)
>
>(under review in TKDE)

In this survey, we present more details of **ProG++** and also release a [repository](https://github.com/WxxShirley/Awesome-Graph-Prompt)ğŸ¦€ for a comprehensive collection of research papers, benchmark datasets, and readily accessible code implementations. 


  
  **The Architecture of ProG++**

  <img height="350" src="/ProG_pipeline.jpg?sanitize=true" />
  <br>
  


**ğŸŒ¹Please cite our work if you find help for you:**


```
@inproceedings{sun2023all,
  title={All in One: Multi-Task Prompting for Graph Neural Networks},
  author={Sun, Xiangguo and Cheng, Hong and Li, Jia and Liu, Bo and Guan, Jihong},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining (KDD'23)},
  year={2023},
  pages = {2120â€“2131},
  location = {Long Beach, CA, USA},
  isbn = {9798400701030},
  url = {https://doi.org/10.1145/3580305.3599256},
  doi = {10.1145/3580305.3599256}
}

@article{sun2023graph,
  title = {Graph Prompt Learning: A Comprehensive Survey and Beyond},
  author = {Sun, Xiangguo and Zhang, Jiawen and Wu, Xixi and Cheng, Hong and Xiong, Yun and Li, Jia},
  year = {2023},
  journal = {arXiv:2311.16534},
  eprint = {2311.16534},
  archiveprefix = {arxiv}
}


```

---

## Quick Start

### Package Dependencies

- PyTorch 1.13.1
- torchmetrics 0.11.4
- torch_geometric 2.2.0

### Pre-train your GNN model

The following codes present a simple example on how to pre-train a GNN model via GraphCL. You can also find a integrated
function ``pretrain()`` in ``no_meta_demo.py``.

```python
from ProG.utils import mkdir, load_data4pretrain
from ProG import PreTrain

mkdir('./pre_trained_gnn/')

pretext = 'GraphCL'  # 'GraphCL', 'SimGRACE'
gnn_type = 'TransformerConv'  # 'GAT', 'GCN'
dataname, num_parts, batch_size = 'CiteSeer', 200, 10

print("load data...")
graph_list, input_dim, hid_dim = load_data4pretrain(dataname, num_parts)

print("create PreTrain instance...")
pt = PreTrain(pretext, gnn_type, input_dim, hid_dim, gln=2)

print("pre-training...")
pt.train(dataname, graph_list, batch_size=batch_size,
         aug1='dropN', aug2="permE", aug_ratio=None,
         lr=0.01, decay=0.0001, epochs=100)


```

### Create Relative Models

```python
from ProG.prompt import GNN, LightPrompt
from torch import nn, optim
import torch

# load pre-trained GNN
gnn = GNN(100, hid_dim=100, out_dim=100, gcn_layer_num=2, gnn_type="TransformerConv")
pre_train_path = './pre_trained_gnn/{}.GraphCL.{}.pth'.format("CiteSeer", "TransformerConv")
gnn.load_state_dict(torch.load(pre_train_path))
print("successfully load pre-trained weights for gnn! @ {}".format(pre_train_path))
for p in gnn.parameters():
    p.requires_grad = False

# prompt with hand-crafted answering template (no answering head tuning)
PG = LightPrompt(token_dim=100, token_num_per_group=100, group_num=6, inner_prune=0.01)

opi = optim.Adam(filter(lambda p: p.requires_grad, PG.parameters()),
                 lr=0.001, weight_decay=0.00001)

lossfn = nn.CrossEntropyLoss(reduction='mean')

```

The above codes are also integrated as a function ``model_create(dataname, gnn_type, num_class, task_type)`` in this
project.

### Prompt learning with hand-crafted answering template

```python
from ProG.data import multi_class_NIG
import torch

train, test, _, _ = multi_class_NIG(dataname, num_class)
gnn, PG, opi, lossfn, _, _ = model_create(dataname, gnn_type, num_class, task_type)
prompt_epoch = 200  # 200
# training stage
PG.train()
emb0 = gnn(train.x, train.edge_index, train.batch)
for j in range(prompt_epoch):
    pg_batch = PG.inner_structure_update()
    pg_emb = gnn(pg_batch.x, pg_batch.edge_index, pg_batch.batch)
    dot = torch.mm(emb0, torch.transpose(pg_emb, 0, 1))
    sim = torch.softmax(dot, dim=1)
    train_loss = lossfn(sim, train.y)
    print('{}/{} training loss: {:.8f}'.format(j, prompt_epoch, train_loss.item()))
    opi.zero_grad()
    train_loss.backward()
    opi.step()
```

### More Detailed Tutorial

For more detailed usage examples w.r.t ``prompt with answer tuning``, ``prompt with meta-learning`` etc. Please check
the demo in:

- ``no_meta_demo.py``
- ``meta_demo.py``

### Compare this new implementation with the raw code

```
Multi-class node classification (100-shots)

                      |      CiteSeer     |
                      |  ACC  | Macro-F1  |
==========================================|
reported in the paper | 80.50 |   80.05   |
(Prompt)              |                   |
------------------------------------------|
this version code     | 81.00 |   81.23   |
(Prompt)              |   (run one time)  | 
==========================================|
reported in the paper | 80.00 ï½œ  80.05   ï½œ
(Prompt w/o h)        |                   ï½œ
------------------------------------------|
this version code     | 79.78 ï½œ  80.01   ï½œ
(Prompt w/o h)        |   (run one time)  ï½œ
==========================================|

```

  
**Kindly note that the comparison takes the same pre-trained pth. The absolute value of performance won't mean much because the final results may vary depending on different
  pre-training states. It would be more interesting to see the relative performance with other training paradigms. **



**Note:**

- The above table is copied from this blog: https://github.com/sheldonresearch/ProG/blob/main/History.md#13-jul-2023

## Citation

bibtex

```
@inproceedings{sun2023all,
  title={All in One: Multi-Task Prompting for Graph Neural Networks},
  author={Sun, Xiangguo and Cheng, Hong and Li, Jia and Liu, Bo and Guan, Jihong},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining (KDD'23)},
  year={2023},
  pages = {2120â€“2131},
  location = {Long Beach, CA, USA},
  isbn = {9798400701030},
  url = {https://doi.org/10.1145/3580305.3599256},
  doi = {10.1145/3580305.3599256}
}
```
```
@article{sun2023graph,
  title = {Graph Prompt Learning: {{A}} Comprehensive Survey and Beyond},
  author = {Sun, Xiangguo and Zhang, Jiawen and Wu, Xixi and Cheng, Hong and Xiong, Yun and Li, Jia},
  year = {2023},
  journal = {arXiv:2311.16534},
  eprint = {2311.16534},
  archiveprefix = {arxiv}
}

```


## Contact

- For More Information, Further discussion, Contact: [Website](https://graphprompt.github.io/)
- Email: xiangguosun at cuhk dot edu dot hk

## Media Coverage

**Media Reports**

- [é¦™æ¸¯é¦–ä½å­¸è€…ç²ACMé ’æœ€ä½³ç ”ç©¶è«–æ–‡ç, é¦™æ¸¯æ–°èç¶², 2023-09-20 15:21](http://www.hkcna.hk/docDetail.jsp?id=100474675&channel=4372)
- [å†…åœ°åŠé¦™æ¸¯é¦–æ¬¡ï¼æ¸¯ä¸­å¤§çš„ä»–ä»¬è·å¾—è¿™é¡¹å›½é™…å¤§å¥–ï¼,é¦™æ¸¯ä¸­æ–‡å¤§å­¦å®˜æ–¹å…¬ä¼—å·ï¼Œ 2023-09-11 21:30](https://mp.weixin.qq.com/s/0AYazi8HD9CGRs0kxqUinw)
- [Two CUHK scholars receive Best Paper Award from ACM SIGKDD Conference 2023, CUHK Focus](https://www.focus.cuhk.edu.hk/20230906/two-cuhk-scholars-receive-best-paper-award-from-acm-sigkdd-conference-2023/)
- [Prof. Cheng Hong and her postdoc fellow Dr. Sun Xiangguo won the best paper award at KDD2023, CUHK SEEM](https://www.se.cuhk.edu.hk/prof-cheng-hong-and-her-postdoc-fellow-dr-sun-xiangguo-won-the-best-paper-award-at-kdd2023/)
- [æ¸¯ç§‘å¤œé—»ï½œé¦™æ¸¯ç§‘å¤§(å¹¿å·)ç†Šè¾‰æ•™æˆã€æä½³æ•™æˆåˆ†åˆ«è£è· ACM SIGKDD2023 æœåŠ¡å¥–ä¸æœ€ä½³è®ºæ–‡å¥–(ç ”ç©¶)](https://mp.weixin.qq.com/s/QCm-QtwNjh6rXrzJ3K2njQ)
- [æ•°æ®ç§‘å­¦ä¸åˆ†æå­¦åŸŸæä½³æ•™æˆè£è·SIGKDD2023æœ€ä½³è®ºæ–‡å¥–ï¼ˆç ”ç©¶ï¼‰ï¼](https://mp.weixin.qq.com/s/3Efakieo9Y9Tj6DTwZoonA)
- [å®æ—¶è¿½è¸ªç§‘ç ”åŠ¨æ€ä¸¨å§šæœŸæ™ºã€Quoc Viet Leç­‰äºº8.9ç²¾é€‰æ–°è®ºæ–‡ï¼Œé™„ChatPaperç»¼è¿°](https://mp.weixin.qq.com/s/nfKiBcLIMcuvNqZT0XgSGA)
- KDD 2023å¥–é¡¹å‡ºç‚‰ï¼šæ¸¯ä¸­æ–‡ã€æ¸¯ç§‘å¤§ç­‰è·æœ€ä½³è®ºæ–‡å¥–ï¼ŒGNNå¤§ç‰›Leskovecè·åˆ›æ–°å¥–
  - [æœºå™¨ä¹‹å¿ƒ](https://mp.weixin.qq.com/s/_JwfqlvFLOyauJgWxw-iWw)
  - [ä¸“çŸ¥](https://mp.weixin.qq.com/s/2XLudB9BFCp8yZgLgbF3sQ)
  - [PaperWeekly](https://mp.weixin.qq.com/s/eZpMdWAG4Lg0r0EZ0O6nVA)
  - [æ·±åº¦å­¦ä¹ æŠ€æœ¯å‰æ²¿](https://mp.weixin.qq.com/s/PhjszSX3RGv3_Nml3dfwsQ)
  - [æ™ºæºç¤¾åŒº](https://hub.baai.ac.cn/view/28475)
- [å¤šç¯‡GNNè®ºæ–‡è·KDD 2023å¤§å¥–, å›¾ç¥ç»ç½‘ç»œä¸æ¨èç³»ç»Ÿ  2023-08-09 16:03](https://mp.weixin.qq.com/s/7DQC-565F8VoqLluU3WwLw)
- [æ¸¯ç§‘å¹¿æ•°æ®ç§‘å­¦ä¸åˆ†æå­¦åŸŸæä½³æ•™æˆè£è·SIGKDD2023æœ€ä½³è®ºæ–‡å¥–ï¼ˆç ”ç©¶ï¼‰ï¼](https://mp.weixin.qq.com/s/6eUT7SE6ew2N7tRCaFE6gQ)

**Online Discussion**

- [LOGSç¬¬2023/08/12æœŸ||KDD 2023 Best Paper Winner å­™ç›¸å›½ ï¼šæç¤ºå­¦ä¹ åœ¨å›¾ç¥ç»ç½‘ç»œä¸­çš„æ¢ç´¢](https://mp.weixin.qq.com/s/vdFCNhgi2wuXscSauGbSgA)
- [Talké¢„å‘Š | KDD'23 Best Paper æ¸¯ä¸­æ–‡å­™ç›¸å›½ï¼šAll in One - æç¤ºå­¦ä¹ åœ¨å›¾ç¥ç»ç½‘ç»œä¸­çš„æ¢ç´¢](https://mp.weixin.qq.com/s/z8AiCwTUn2TvY8tzB4NjVg)
- [All in One Multi-Task Prompting for Graph Neural Networks è®ºæ–‡è§£è¯»](https://www.bilibili.com/video/BV1Rk4y1V7wA/?share_source=copy_web&vd_source=dc2c6946b0127024c2225b0e695d9a83)
- [kdd2023æœ€ä½³è®ºæ–‡](https://www.bilibili.com/video/BV1Uu4y1B7zp/?share_source=copy_web&vd_source=dc2c6946b0127024c2225b0e695d9a83)
- [All in One: Multi-task Prompting for Graph Neural Networksï¼ˆKDD 2023 Best Paper](https://zhuanlan.zhihu.com/p/650958869)
- [æ€ä¹ˆè¯„ä»·KDD23çš„best paperï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/617300883)

**Other research papers released by us**
- [æœ€æ–°å›¾å¤§æ¨¡å‹ç»¼è¿°ï¼šç”±æ¸¯ç§‘å¹¿ã€æ¸¯ä¸­æ–‡ã€æ¸…åè”åˆå‘å¸ƒï¼Œè¯¦è¿°ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†å›¾ä»»åŠ¡çš„è¿›å±•ä¸æŒ‘æˆ˜](https://mp.weixin.qq.com/s/hohAfy04rApaaqz6_3EdsQ)
- [å¤§æ¨¡å‹å’Œå›¾å¦‚ä½•ç»“åˆï¼Ÿæœ€æ–°ã€Šå›¾é‡è§å¤§å‹è¯­è¨€æ¨¡å‹ã€‹ç»¼è¿°ï¼Œè¯¦è¿°æœ€æ–°è¿›å±•](https://mp.weixin.qq.com/s/maqKuu9lVqEDpSptBqwoWg)
- [é¦™æ¸¯ä¸­æ–‡é¢†è¡”æ¸¯ç§‘å¹¿ã€å¤æ—¦é‡ç£…å‘å¸ƒï¼šè¿ˆå‘é€šç”¨å›¾æ™ºèƒ½çš„æ–°æ–¹æ³•ï¼Œå›¾æç¤ºå­¦ä¹ è¿›å±•ä¸æŒ‘æˆ˜](https://mp.weixin.qq.com/s/NvfgtXLUX2MWu0U2p7RKEQ)
- [é¦™æ¸¯ä¸­æ–‡é¢†è¡”æ¸¯ç§‘å¹¿ã€å¤æ—¦é‡ç£…å‘å¸ƒï¼šè¿ˆå‘é€šç”¨å›¾æ™ºèƒ½çš„æ–°æ–¹æ³•ï¼Œå›¾æç¤ºå­¦ä¹ è¿›å±•ä¸æŒ‘æˆ˜](https://mp.weixin.qq.com/s/zSTFTgKGaOXbOC0kKT8raQ)
- [å›¾ä¸Šå¦‚ä½•æç¤ºï¼Ÿæ¸¯ä¸­æ–‡ç­‰æœ€æ–°ã€Šå›¾æç¤ºå­¦ä¹ ã€‹å…¨é¢ç»¼è¿°ï¼Œè¯¦è¿°å›¾æç¤ºåˆ†ç±»ä½“ç³»](https://mp.weixin.qq.com/s/6k7ZTVM0Hj8bO4iAjOERAQ)

## Call for Contributors!

Once you are invited as a contributor, you would be asked to follow the following steps:

- step 1. create a temp branch (e.g. ``xgTemp``) from the ``main`` branch (latest branch). 
- step 2. fetch ``origin/xgTemp`` to your local ``xgTemp``, and make your own changes via PyCharm etc.
- step 3. push your changes from local ``xgTemp`` to your github cloud branch: ``origin/xgTemp``.
- step 4. open a pull request to merge from your branch to ``main``.

When you finish all these jobs. I will get a notification and approve merging your branch to ``main``.
Once I finish, I will delete your branch, and next time you will repeat the above jobs.


A widely tested ``main`` branch will then be merged to the ``stable`` branch and a new version will be released based on ``stable`` branch.
